{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60573d4-25b8-49fb-aa29-06b03337de65",
   "metadata": {},
   "outputs": [],
   "source": [
    "Answer 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ed7a20-f99c-4892-8e8f-05cb4b6db1d4",
   "metadata": {},
   "source": [
    "Let S be the event that an employee is a smoker, and H be the event that the employee uses the health insurance plan. We are given:\n",
    "\n",
    "P(H) = 0.7 (probability that an employee uses the health insurance plan)\n",
    "P(S|H) = 0.4 (probability that an employee who uses the plan is a smoker)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e575649c-8d87-4cd4-a6ce-4699736d9158",
   "metadata": {},
   "source": [
    "We want to find P(S|H), the probability that an employee who uses the plan is a smoker. By Bayes' theorem, we have:\n",
    "\n",
    "P(S|H) = P(H|S) * P(S) / P(H)\n",
    "\n",
    "We can calculate P(H|S) using the formula for conditional probability:\n",
    "\n",
    "P(H|S) = P(H ∩ S) / P(S)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efef44fd-8b4f-43f2-8adf-03135b263a9e",
   "metadata": {},
   "source": [
    "We don't have P(H ∩ S) directly, but we can use the formula for conditional probability again:\n",
    "\n",
    "P(H ∩ S) = P(S|H) * P(H)\n",
    "\n",
    "Putting it all together, we get:\n",
    "\n",
    "P(S|H) = P(S ∩ H) / P(H)\n",
    "= P(S|H) * P(H) / P(H)\n",
    "= P(S|H) * P(H ∩ S) / P(S)\n",
    "= (0.4 * 0.7) / 0.7\n",
    "= 0.4\n",
    "\n",
    "Therefore, the probability that an employee is a smoker given that he/she uses the health insurance plan is 0.4, or 40%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd9475e-0eeb-4fdd-bc1f-709193318870",
   "metadata": {},
   "outputs": [],
   "source": [
    "Answer 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85100c5-2bc5-46e8-a6f3-4d398bfd5b7f",
   "metadata": {},
   "source": [
    "Bernoulli Naive Bayes and Multinomial Naive Bayes are both variations of the Naive Bayes algorithm, but they differ in how they handle the feature variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02f4ff3-d01d-4976-a45b-4eccc5c44708",
   "metadata": {},
   "source": [
    "Bernoulli Naive Bayes is used when the feature variables are binary (0 or 1). It assumes that the presence or absence of a feature is equally important in predicting the class label. For example, in text classification, a Bernoulli Naive Bayes model would treat the presence or absence of a word in a document as a binary feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0f332c-96b5-4cd2-b95c-8309e7a1f355",
   "metadata": {},
   "source": [
    "On the other hand, Multinomial Naive Bayes is used when the feature variables are discrete counts, such as word frequencies in a document. \n",
    "\n",
    "It assumes that the frequency of occurrence of a feature is important in predicting the class label. For example, in text classification, a Multinomial Naive Bayes model would use the frequency of a word in a document as a feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a43faeb-e56f-41de-8d4d-9aa4e7ae1e9d",
   "metadata": {},
   "source": [
    "In summary, Bernoulli Naive Bayes assumes binary features while Multinomial Naive Bayes assumes discrete count features. Bernoulli Naive Bayes treats the presence or absence of a feature as equally important, while Multinomial Naive Bayes uses the frequency of occurrence of a feature. The choice between the two depends on the type of feature variables and the specific problem at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9f06af-d8e5-4aee-a80e-9667dfaaaa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "Answer 3:\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ba42c7-b929-41d7-928b-4afb2870c196",
   "metadata": {},
   "source": [
    "In Bernoulli Naive Bayes, missing values can be handled in a couple of ways:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6068b5ad-7e7d-4dd4-8c21-1749a27c6dba",
   "metadata": {},
   "source": [
    "1.Deletion: One option is to simply remove the instances with missing values from the dataset. This is a common approach when the percentage of missing values is low and removing the instances does not significantly affect the performance of the model.\n",
    "\n",
    "2.Imputation: Another option is to impute the missing values with some estimate. One way to do this is to impute the missing values with the mode (most frequent value) of the corresponding feature. This assumes that the missing values are most likely to have the same value as the mode. Alternatively, missing values can be imputed with a value between 0 and 1 that represents the probability of the feature being present, based on the overall frequency of the feature in the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8617e480-4dd2-40b5-8bb8-8fb3a7a52833",
   "metadata": {},
   "source": [
    "\n",
    "Regardless of the method used, it is important to note that Bernoulli Naive Bayes assumes that the missing values are missing completely at random (MCAR), meaning that the probability of an instance having missing values is independent of its class label and the values of the other features. If this assumption is not met, the imputation method may introduce bias in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f813aabd-e171-4023-9da8-b3f287064710",
   "metadata": {},
   "outputs": [],
   "source": [
    "Answer 4:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb94cd75-1223-4a46-be0f-42c0da8c785c",
   "metadata": {},
   "source": [
    "Yes, Gaussian Naive Bayes can be used for multi-class classification. In the multi-class classification setting, Gaussian Naive Bayes can be trained on a dataset with more than two classes by using the \"one-vs-all\" or \"one-vs-rest\" approach.\n",
    "\n",
    "In this approach, a separate Gaussian Naive Bayes model is trained for each class, treating the instances of that class as the positive class and the instances of all other classes as the negative class. When making predictions for a new instance, the model that assigns the highest probability to that instance is chosen as the predicted class label."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365d2e0a-44a2-49bc-ba30-f29063e9edfe",
   "metadata": {},
   "source": [
    "Alternatively, Gaussian Naive Bayes can also be used for multi-class classification by directly estimating the conditional probability distribution of the class variable given the feature variables for all classes simultaneously. However, this approach requires more complex computations and is less commonly used in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba125f9f-91bf-4a86-8c14-46d2ba0ff724",
   "metadata": {},
   "outputs": [],
   "source": [
    "Answer 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13eade03-5e00-4967-bf30-28165ada31ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "First, we need to import the necessary libraries and load the Spambase dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a331b9b-7978-433b-badf-51ba6f5d37c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\"\n",
    "data = pd.read_csv(url, header=None)\n",
    "\n",
    "# Split the dataset into features and labels\n",
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c878871e-5b86-42b5-87ac-6fa5cca2fe03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4596</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.142</td>\n",
       "      <td>3</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4597</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.555</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.404</td>\n",
       "      <td>6</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4599</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.147</td>\n",
       "      <td>5</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4600</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.250</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4601 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1     2    3     4     5     6     7     8     9   ...     48  \\\n",
       "0     0.00  0.64  0.64  0.0  0.32  0.00  0.00  0.00  0.00  0.00  ...  0.000   \n",
       "1     0.21  0.28  0.50  0.0  0.14  0.28  0.21  0.07  0.00  0.94  ...  0.000   \n",
       "2     0.06  0.00  0.71  0.0  1.23  0.19  0.19  0.12  0.64  0.25  ...  0.010   \n",
       "3     0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.000   \n",
       "4     0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.000   \n",
       "...    ...   ...   ...  ...   ...   ...   ...   ...   ...   ...  ...    ...   \n",
       "4596  0.31  0.00  0.62  0.0  0.00  0.31  0.00  0.00  0.00  0.00  ...  0.000   \n",
       "4597  0.00  0.00  0.00  0.0  0.00  0.00  0.00  0.00  0.00  0.00  ...  0.000   \n",
       "4598  0.30  0.00  0.30  0.0  0.00  0.00  0.00  0.00  0.00  0.00  ...  0.102   \n",
       "4599  0.96  0.00  0.00  0.0  0.32  0.00  0.00  0.00  0.00  0.00  ...  0.000   \n",
       "4600  0.00  0.00  0.65  0.0  0.00  0.00  0.00  0.00  0.00  0.00  ...  0.000   \n",
       "\n",
       "         49   50     51     52     53     54   55    56  57  \n",
       "0     0.000  0.0  0.778  0.000  0.000  3.756   61   278   1  \n",
       "1     0.132  0.0  0.372  0.180  0.048  5.114  101  1028   1  \n",
       "2     0.143  0.0  0.276  0.184  0.010  9.821  485  2259   1  \n",
       "3     0.137  0.0  0.137  0.000  0.000  3.537   40   191   1  \n",
       "4     0.135  0.0  0.135  0.000  0.000  3.537   40   191   1  \n",
       "...     ...  ...    ...    ...    ...    ...  ...   ...  ..  \n",
       "4596  0.232  0.0  0.000  0.000  0.000  1.142    3    88   0  \n",
       "4597  0.000  0.0  0.353  0.000  0.000  1.555    4    14   0  \n",
       "4598  0.718  0.0  0.000  0.000  0.000  1.404    6   118   0  \n",
       "4599  0.057  0.0  0.000  0.000  0.000  1.147    5    78   0  \n",
       "4600  0.000  0.0  0.125  0.000  0.000  1.250    5    40   0  \n",
       "\n",
       "[4601 rows x 58 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734b6102-cdd6-452b-b8ce-33cccacc58a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Next, we can train and evaluate the performance of each Naive Bayes classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "156f805e-cc10-47da-9bc6-779971ca0224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bernoulli Naive Bayes classifier\n",
    "bnb = BernoulliNB()\n",
    "bnb_scores = cross_val_score(bnb, X, y, cv=10)\n",
    "bnb_accuracy = bnb_scores.mean()\n",
    "bnb_precision = cross_val_score(bnb, X, y, cv=10, scoring='precision').mean()\n",
    "bnb_recall = cross_val_score(bnb, X, y, cv=10, scoring='recall').mean()\n",
    "bnb_f1_score = cross_val_score(bnb, X, y, cv=10, scoring='f1').mean()\n",
    "\n",
    "# Multinomial Naive Bayes classifier\n",
    "mnb = MultinomialNB()\n",
    "mnb_scores = cross_val_score(mnb, X, y, cv=10)\n",
    "mnb_accuracy = mnb_scores.mean()\n",
    "mnb_precision = cross_val_score(mnb, X, y, cv=10, scoring='precision').mean()\n",
    "mnb_recall = cross_val_score(mnb, X, y, cv=10, scoring='recall').mean()\n",
    "mnb_f1_score = cross_val_score(mnb, X, y, cv=10, scoring='f1').mean()\n",
    "\n",
    "# Gaussian Naive Bayes classifier\n",
    "gnb = GaussianNB()\n",
    "gnb_scores = cross_val_score(gnb, X, y, cv=10)\n",
    "gnb_accuracy = gnb_scores.mean()\n",
    "gnb_precision = cross_val_score(gnb, X, y, cv=10, scoring='precision').mean()\n",
    "gnb_recall = cross_val_score(gnb, X, y, cv=10, scoring='recall').mean()\n",
    "gnb_f1_score = cross_val_score(gnb, X, y, cv=10, scoring='f1').mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987fe5bf-0355-49f5-80ef-f33d2202bca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Finally, we can report the performance metrics for each classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00fd44e3-366d-43ef-beae-6c299b0ec5cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Naive Bayes Classifier\n",
      "Accuracy: 0.8839380364047911\n",
      "Precision: 0.8869617393737383\n",
      "Recall: 0.8152389047416673\n",
      "F1 Score: 0.8481249015095276\n",
      "Multinomial Naive Bayes Classifier\n",
      "Accuracy: 0.7863496180326323\n",
      "Precision: 0.7393175533565436\n",
      "Recall: 0.7214983911116508\n",
      "F1 Score: 0.7282909724016348\n",
      "Gaussian Naive Bayes Classifier\n",
      "Accuracy: 0.8217730830896915\n",
      "Precision: 0.7103733928118492\n",
      "Recall: 0.9569516119239877\n",
      "F1 Score: 0.8130660909542995\n"
     ]
    }
   ],
   "source": [
    "print(\"Bernoulli Naive Bayes Classifier\")\n",
    "print(\"Accuracy:\", bnb_accuracy)\n",
    "print(\"Precision:\", bnb_precision)\n",
    "print(\"Recall:\", bnb_recall)\n",
    "print(\"F1 Score:\", bnb_f1_score)\n",
    "\n",
    "print(\"Multinomial Naive Bayes Classifier\")\n",
    "print(\"Accuracy:\", mnb_accuracy)\n",
    "print(\"Precision:\", mnb_precision)\n",
    "print(\"Recall:\", mnb_recall)\n",
    "print(\"F1 Score:\", mnb_f1_score)\n",
    "\n",
    "print(\"Gaussian Naive Bayes Classifier\")\n",
    "print(\"Accuracy:\", gnb_accuracy)\n",
    "print(\"Precision:\", gnb_precision)\n",
    "print(\"Recall:\", gnb_recall)\n",
    "print(\"F1 Score:\", gnb_f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10a0e99-e1bc-4b2e-8b46-9370c3f43b0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
