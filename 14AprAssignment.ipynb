{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc1d111-0b4e-491a-8891-0fe3a5f0cc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Answer 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dd23b7-1336-4730-b36c-5338fb160932",
   "metadata": {},
   "outputs": [],
   "source": [
    "First, we need to import the necessary libraries and load the heart disease dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8db30257-4a21-40c2-864b-f76a160b3b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://drive.google.com/uc?id=1bGoIE4Z2kG5nyh-fGZAJ7LH0ki3UfmSJ\"\n",
    "data = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99237f13-e927-4596-ae0a-c89fb1f45f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0     63    1   3       145   233    1        0      150      0      2.3   \n",
       "1     37    1   2       130   250    0        1      187      0      3.5   \n",
       "2     41    0   1       130   204    0        0      172      0      1.4   \n",
       "3     56    1   1       120   236    0        1      178      0      0.8   \n",
       "4     57    0   0       120   354    0        1      163      1      0.6   \n",
       "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "298   57    0   0       140   241    0        1      123      1      0.2   \n",
       "299   45    1   3       110   264    0        1      132      0      1.2   \n",
       "300   68    1   0       144   193    1        1      141      0      3.4   \n",
       "301   57    1   0       130   131    0        1      115      1      1.2   \n",
       "302   57    0   1       130   236    0        0      174      0      0.0   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "0        0   0     1       1  \n",
       "1        0   0     2       1  \n",
       "2        2   0     2       1  \n",
       "3        2   0     2       1  \n",
       "4        2   0     2       1  \n",
       "..     ...  ..   ...     ...  \n",
       "298      1   0     3       0  \n",
       "299      1   0     3       0  \n",
       "300      1   2     3       0  \n",
       "301      1   1     3       0  \n",
       "302      1   1     2       0  \n",
       "\n",
       "[303 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6eb4659-8024-43d2-8a80-9a1738f187bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17fb3023-6598-4daa-87c9-e417bbc0cfe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_110/580326495.py:4: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data.iloc[:, [0,3,4,7,9]] = imputer.fit_transform(data.iloc[:, [0,3,4,7,9]])\n"
     ]
    }
   ],
   "source": [
    "# Handle missing values\n",
    "\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "data.iloc[:, [0,3,4,7,9]] = imputer.fit_transform(data.iloc[:, [0,3,4,7,9]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f28a4df3-e207-4df6-9bc7-7d83ad5b847a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "data.iloc[:, 2] = label_encoder.fit_transform(data.iloc[:, 2])\n",
    "data.iloc[:, 11] = label_encoder.fit_transform(data.iloc[:, 11])\n",
    "data.iloc[:, 12] = label_encoder.fit_transform(data.iloc[:, 12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "600ece7c-5c30-44e4-bb5c-b69023f49bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale numerical features\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data.iloc[:, [0,3,4,7,9]] = scaler.fit_transform(data.iloc[:, [0,3,4,7,9]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6dbdca-0a9f-4e4a-ad34-90de1d81329f",
   "metadata": {},
   "source": [
    "Here's what we did:\n",
    "\n",
    "1.We used the SimpleImputer class from scikit-learn to fill in missing values with the mean of the column. 2.We selected the columns that contain missing values by their indices.\n",
    "3.We used the LabelEncoder class to encode the categorical variables. We selected the columns to be encoded by their indices.\n",
    "4.We used the StandardScaler class to scale the numerical features to have a mean of 0 and a standard deviation of 1. We selected the columns to be scaled by their indices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70989c89-a02e-4ebf-86bc-953d448b6f38",
   "metadata": {},
   "source": [
    "After preprocessing, we split the dataset into training and testing sets, trained a random forest classifier on the training set, and evaluated its performance on the testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad77e758-f151-458e-846b-0b9af6b021ac",
   "metadata": {},
   "source": [
    "Preprocessing is an important step in machine learning, as it can help to improve the performance of models and ensure that they are robust to missing data and categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17de5be-857a-45d5-9728-c5dd984928d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Answer 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00de5a92-fc11-4da7-a376-074d081d5155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into features and labels\n",
    "\n",
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6dd8618d-f92b-43b2-95ec-12588bf90f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "331d609e-be36-47cb-bf86-c3c92e5fbc0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(212, 13)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "536485a9-1404-4d15-bb70-b0788732519f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91, 13)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b3afaac-6439-4269-a4b9-77f9ffc934b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(212,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27e2d554-6b63-479a-b0c7-df2ce8161289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c4e1e26-67df-4c48-8205-a8170192eb04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (212, 13) (212,)\n",
      "Testing set shape: (91, 13) (91,)\n"
     ]
    }
   ],
   "source": [
    "# Print the shapes of the training and testing sets\n",
    "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Testing set shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c89689-b19b-42ee-b03e-48892c4a5ab7",
   "metadata": {},
   "source": [
    "Here's what we did:\n",
    "\n",
    "1. We loaded the heart disease dataset using pandas.\n",
    "2. We split the dataset into features (X) and labels (y).\n",
    "3. We used the train_test_split function from scikit-learn to split the dataset into a training set (X_train, y_train) and a test set (X_test, y_test). We set the test_size parameter to 0.3, which means that 30% of the data is reserved for testing, and we set the random_state parameter to 42 for reproducibility.\n",
    "4. We printed the shapes of the training and testing sets to verify that the split was done correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19889e1-4d5f-45ab-b0db-5062b9aef3ea",
   "metadata": {},
   "source": [
    "Splitting the dataset into training and testing sets is an important step in machine learning, as it allows us to train the model on one set of data and evaluate its performance on another set of data that it has not seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9013fc4-b24c-4b6c-ac4c-54ea5b628e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "Answer 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c97be721-ff49-4414-84b2-93fbc9bc99a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=10, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=10, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=10, random_state=42)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random forest classifier with 100 trees and a max depth of 10\n",
    "rfc = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a57b4d3-6dfe-4d55-ad1e-eb0f5ebaf900",
   "metadata": {},
   "source": [
    "Here's what we did:\n",
    "\n",
    "1. We imported the RandomForestClassifier class from scikit-learn's ensemble module.\n",
    "2. We created a RandomForestClassifier object called rfc with 100 trees and a maximum depth of 10 for each tree. We set the random_state parameter to 42 for reproducibility.\n",
    "3. We trained the model on the training data (X_train and y_train) using the fit method of the rfc object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8319404f-4709-4460-8d0c-2017a12e5ddd",
   "metadata": {},
   "source": [
    "The random forest algorithm works by creating multiple decision trees and combining their predictions. Each tree is trained on a random subset of the training data, and at each split, the algorithm selects a random subset of the features to consider.\n",
    "\n",
    "The number of trees and the maximum depth of each tree are hyperparameters that we can tune to improve the performance of the model. In this example, we used 100 trees and a maximum depth of 10 for each tree, but these values may not be optimal for every dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f76013b-2d60-4b4d-ac47-7b57d54ac776",
   "metadata": {},
   "outputs": [],
   "source": [
    "Answwer 4:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d9f347-b4fa-4668-999d-9d9b0a7cd9ec",
   "metadata": {},
   "source": [
    " how to evaluate the performance of the random forest classifier on the test set using scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f274c43-08cb-4a0e-8b8c-748bfd19c612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8131868131868132\n",
      "Precision: 0.8367346938775511\n",
      "Recall: 0.82\n",
      "F1 score: 0.8282828282828283\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test data\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4c849e-aeff-4a74-b19e-1d74000fb707",
   "metadata": {},
   "source": [
    "Here's what we did:\n",
    "\n",
    "1.We imported the accuracy_score, precision_score, recall_score, and f1_score functions from scikit-learn's metrics module.\n",
    "2.We used the predict method of the rfc object to make predictions on the test data (X_test).\n",
    "3.We calculated the accuracy, precision, recall, and F1 score of the predictions using the corresponding functions from scikit-learn's metrics module. We passed in the true labels (y_test) and the predicted labels (y_pred) as arguments.\n",
    "4.We printed the evaluation metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d0c78e-ef7d-4ee5-9fca-ac05f5a9f12c",
   "metadata": {},
   "source": [
    "The accuracy is a measure of the overall performance of the model, the precision measures the proportion of true positives among all positive predictions, the recall measures the proportion of true positives among all actual positives, and the F1 score is the harmonic mean of precision and recall. \n",
    "\n",
    "These metrics can give us a better understanding of how well the model is performing on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9514bbe6-a481-43ae-847c-9569f9552415",
   "metadata": {},
   "outputs": [],
   "source": [
    "Answer 5:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd060f13-3f7e-49cf-9981-ae8e79df792a",
   "metadata": {},
   "source": [
    "Here's an example of how to get the feature importance scores from the random forest classifier and visualize them using a bar chart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d45e608-d93a-4351-ab0b-fac7c2e6dd47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get feature importances from the random forest classifier\n",
    "importances = rfc.feature_importances_\n",
    "\n",
    "# Get the indices of the top 5 features\n",
    "indices = importances.argsort()[-5:]\n",
    "\n",
    "# Get the names of the top 5 features\n",
    "names = [X.columns[i] for i in indices]\n",
    "\n",
    "# Plot the feature importances as a bar chart\n",
    "plt.barh(range(len(indices)), importances[indices], align='center')\n",
    "plt.yticks(range(len(indices)), names)\n",
    "plt.xlabel(\"Feature importance\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755bfc74-eea2-4aff-a940-c7c6bd59ee32",
   "metadata": {},
   "source": [
    "Here's what we did:\n",
    "\n",
    "1.We imported the matplotlib.pyplot module for visualizing the feature importances.\n",
    "2.We used the feature_importances_ attribute of the rfc object to get the feature importance scores.\n",
    "3.We used the argsort method of the importances array to get the indices of the top 5 features.\n",
    "4.We used the indices to get the names of the top 5 features from the X dataframe.\n",
    "5.We plotted the feature importances as a horizontal bar chart using the barh function of pyplot. We passed in the indices and importances as arguments, set the align parameter to 'center' to center the bars on the y-axis ticks, and set the y-axis ticks to the feature names using the yticks function. We also added a label to the x-axis and displayed the plot using the show function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159cac98-21a9-4f71-a98d-1099a9979eb7",
   "metadata": {},
   "source": [
    "This code should give you a bar chart that shows the relative importance of the top 5 features in predicting heart disease risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e79093b-4646-4c60-9bd1-b12b037d7e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Answwer 6:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937ba966-99a7-454a-8421-052dc2063ccf",
   "metadata": {},
   "source": [
    "Here's an example of how to tune the hyperparameters of the random forest classifier using grid search and 5-fold cross-validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "830bbbac-61e4-441c-87b0-ada0de1c1a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 50}\n",
      "Best score:  0.8440753045404208\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the hyperparameter grid to search over\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'max_depth': [5, 10, 15, 20],\n",
    "    'min_samples_split': [2, 4, 6],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Create a grid search object\n",
    "grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5)\n",
    "\n",
    "# Fit the grid search object to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters and corresponding score\n",
    "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abea70d-cc83-494b-8517-ec73d27290d1",
   "metadata": {},
   "source": [
    "Here's what we did:\n",
    "\n",
    "1.We imported the GridSearchCV class from the sklearn.model_selection module to perform the grid search.\n",
    "2.We defined a dictionary param_grid that specifies the hyperparameters to search over and the values to try for each hyperparameter.\n",
    "3.We created a GridSearchCV object by passing in a new RandomForestClassifier object, the param_grid dictionary, and the number of folds for cross-validation (cv=5).\n",
    "4.We fit the grid_search object to the training data (X_train and y_train).\n",
    "5.We printed the best hyperparameters and corresponding score using the best_params_ and best_score_ attributes of the grid_search object.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499fab57-787b-49fb-b1c1-ec58acbf5ffa",
   "metadata": {},
   "source": [
    "\n",
    "This code should perform a grid search over the specified hyperparameters and print out the best hyperparameters and corresponding score. You can modify the param_grid dictionary to include other hyperparameters or values to try.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c773b8-b05e-43c1-b13d-2ae7e9496464",
   "metadata": {},
   "outputs": [],
   "source": [
    "Answer 7:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7821eab-ab03-4978-ae67-330676bdd0a1",
   "metadata": {},
   "source": [
    "Here's an example of how to report the best set of hyperparameters and corresponding performance metrics for the tuned model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "333ccf3a-9502-4304-9883-070a2f853f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 50}\n",
      "Best score:  0.8440753045404208\n",
      "Accuracy:  0.8351648351648352\n",
      "Precision:  0.8301886792452831\n",
      "Recall:  0.88\n",
      "F1 score:  0.8543689320388349\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Print the best hyperparameters and corresponding score\n",
    "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)\n",
    "\n",
    "# Get the best model from the grid search\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Print the performance metrics of the best model\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 score: \", f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb2e340-bc66-4b88-ac2d-81cec368f29b",
   "metadata": {},
   "source": [
    "Here's what we did:\n",
    "\n",
    "1.We printed the best hyperparameters and corresponding score found by the grid search using the best_params_ and best_score_ attributes of the grid_search object.\n",
    "2.We got the best model from the grid search by accessing the best_estimator_ attribute of the grid_search object.\n",
    "3.We evaluated the best model on the test set by making predictions with predict and calculating the performance metrics using accuracy_score, precision_score, recall_score, and f1_score.\n",
    "4.We printed the performance metrics of the best model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45be70ec-8555-4349-aeda-a9d6f6466877",
   "metadata": {},
   "source": [
    "To compare the performance of the tuned model with the default model, you can print the performance metrics of the default model on the test set as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b971d25b-f888-4103-8930-202a898beb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the default model on the test set\n",
    "y_pred_default = rf_default.predict(X_test)\n",
    "accuracy_default = accuracy_score(y_test, y_pred_default)\n",
    "precision_default = precision_score(y_test, y_pred_default)\n",
    "recall_default = recall_score(y_test, y_pred_default)\n",
    "f1_default = f1_score(y_test, y_pred_default)\n",
    "\n",
    "# Print the performance metrics of the default model\n",
    "print(\"Default Model Performance Metrics:\")\n",
    "print(\"Accuracy: \", accuracy_default)\n",
    "print(\"Precision: \", precision_default)\n",
    "print(\"Recall: \", recall_default)\n",
    "print(\"F1 score: \", f1_default)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1317a07e-46d0-43e7-b9ad-d6041e4418aa",
   "metadata": {},
   "source": [
    "This will print the performance metrics of the default model on the test set. You can compare these metrics with the ones obtained for the tuned model to see if there was an improvement in performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4c7e2f-c7de-474d-9c0e-5b6efba58d9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ffc853-15ba-44f3-8301-38311d44670a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Answer 8:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac41709a-2458-465f-b641-1baab5081641",
   "metadata": {},
   "source": [
    "To visualize the decision boundaries of the random forest classifier, we can use a scatter plot of two of the most important features and color-code the points based on their predicted class. Here's an example of how to do this using the matplotlib library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda84ec5-21d8-481d-83bf-ccef88f59552",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select two of the most important features\n",
    "importances = rf_tuned.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "top_two_idx = indices[:2]\n",
    "X_plot = X_test[:, top_two_idx]\n",
    "# X_plot = X_test[:, [2, 12]]\n",
    "\n",
    "# Create a meshgrid of points for the two features\n",
    "x_min, x_max = X_plot[:, 0].min() - 1, X_plot[:, 0].max() + 1\n",
    "y_min, y_max = X_plot[:, 1].min() - 1, X_plot[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),\n",
    "                     np.arange(y_min, y_max, 0.01))\n",
    "\n",
    "# Make predictions for the meshgrid points using the tuned model\n",
    "Z = best_model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Plot the decision boundaries and the scatter plot of the test set\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.contourf(xx, yy, Z, alpha=0.4, cmap='viridis')\n",
    "plt.scatter(X_plot[:, 0], X_plot[:, 1], c=y_test, s=20, edgecolor='k', cmap='viridis')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Maximum heart rate achieved')\n",
    "plt.title('Random Forest Classifier Decision Boundaries')\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e1c782-c30e-4a1f-acd0-24546d966614",
   "metadata": {},
   "source": [
    "Here's what we did:\n",
    "\n",
    "1.We selected two of the most important features using their indices in the X_test array.\n",
    "2.We created a meshgrid of points for the two features using np.meshgrid.\n",
    "3.We made predictions for the meshgrid points using the tuned model.\n",
    "4.We plotted the decision boundaries using plt.contourf and the scatter plot of the test set using plt.scatter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ca911b-d742-4bfc-b1bb-a27f156d2c65",
   "metadata": {},
   "source": [
    "The resulting plot shows the decision boundaries of the random forest classifier for the two selected features:\n",
    "\n",
    "We can see that the decision boundaries are non-linear and can capture complex interactions between the features. However, there are still some limitations of the model for predicting heart disease risk:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46d5722-05dd-4186-9a9a-0d7522e85125",
   "metadata": {},
   "source": [
    "1.The model assumes that the relationship between the features and the target is additive and independent, which may not be the case in reality.\n",
    "2.The model may not capture all relevant features or interactions between them, leading to errors in predictions.\n",
    "3.The model is based on a fixed set of input features and may not be able to adapt to new or changing features that are relevant for predicting heart disease risk."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e014452a-db78-4aa5-95a3-a95bbd26f688",
   "metadata": {},
   "source": [
    "Despite these limitations, the random forest classifier can still be a useful tool for predicting heart disease risk and informing clinical decision making. However, its predictions should be interpreted with caution and validated with additional tests or expert knowledge."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
